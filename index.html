<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="WalkVLM">
    <meta name="keywords" content="Text-to-Video, Diffusion Model">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ILDiff</title>

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>


    <style>
        .left-align {
            text-align: left;
        }
        .center-align {
            text-align: center;
        }
    </style>

</head>



<body>


<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">
                <img class="center" width="170" height="100" src="assets/walkvlm2.png">
                : Aid Visually Impaired People Walking by Vision Language Model
            </h2>
            <div class="is-size-5 publication-authors">

                            <div class="column has-text-centered">
              <div class="publication-links">


                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv (Released Later)</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code & Dataset (Released Later)</span>
                    </a>
                </span>
              </div>
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
Approximately 200 million individuals around the world suffer from varying degrees of visual impairment, making it crucial to leverage AI technology to offer walking assistance for these people.
With the recent progress of vision-language models (VLMs), employing VLMs to improve this field has emerged as a popular research topic.
However, most existing methods are studied on self-built question-answering datasets, lacking a unified training and testing benchmark for walk guidance.
Moreover, in blind walking task, it is necessary to perform real-time streaming video parsing and generate concise yet informative reminders, which poses a great challenge for VLMs that suffer from redundant responses and low inference efficiency.
<b>In this paper, we firstly release a diverse, extensive, and unbiased walking awareness dataset, containing 12k video-manual annotation pairs from Europe and Asia to provide a fair training and testing benchmark for blind walking task.
Furthermore, a WalkVLM model is proposed, which employs chain of thought for hierarchical planning to generate concise but informative reminders and utilizes temporal-aware adaptive prediction to reduce the temporal redundancy of reminders.</b>
Finally, we have established a solid benchmark for blind walking task and verified the advantages of WalkVLM in stream video processing for this task compared to other VLMs.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->


<!--        -->


    <section class="section" id="background">
        <h2 class="title is-3">Background</h2>


        <hr />
        <h4 class="title is-5">How the world looks like to visually impairment people?</h4>

        <!-- 视频容器 -->
        <div class="video-container">
            <div class="video-item">
                <video controls>
                    <source src="https://sprproxy-1258344707.cos.ap-shanghai.myqcloud.com/seraphyuan/ilabel/blind_vlm/background/1.mp4" type="video/mp4">
<!--                    Your browser does not support the video tag.-->
                </video>
            </div>
            <!-- 重复 .video-item 直到你添加完所有的视频 -->
            <div class="video-item">
                <video controls>
                    <source src="https://sprproxy-1258344707.cos.ap-shanghai.myqcloud.com/seraphyuan/ilabel/blind_vlm/background/2.mp4" type="video/mp4">
<!--                    Your browser does not support the video tag.-->
                </video>
            </div>
        </div>

        <h2 class="title is-3"></h2>

                <h2 class="title is-3"></h2>

                <h2 class="title is-3"></h2>

                <h2 class="title is-3"></h2>

        <hr />

        <h4 class="title is-5">They are helpless, wandering, and lack the light of life.</h4>

                <!-- 视频容器 -->
        <div class="video-container">
            <div class="video-item">
                <video controls>
                    <source src="https://sprproxy-1258344707.cos.ap-shanghai.myqcloud.com/seraphyuan/ilabel/blind_vlm/background/bk_4s.mp4" type="video/mp4">
<!--                    Your browser does not support the video tag.-->
                </video>
            </div>
            <!-- 重复 .video-item 直到你添加完所有的视频 -->
            <div class="video-item">
                <video controls>
                    <source src="https://sprproxy-1258344707.cos.ap-shanghai.myqcloud.com/seraphyuan/ilabel/blind_vlm/background/bk_2s.mp4" type="video/mp4">
<!--                    Your browser does not support the video tag.-->
                </video>
            </div>
<!--            &lt;!&ndash; 重复 .video-item 直到你添加完所有的视频 &ndash;&gt;-->
<!--            <div class="video-item">-->
<!--                <video controls>-->
<!--                    <source src="https://sprproxy-1258344707.cos.ap-shanghai.myqcloud.com/seraphyuan/ilabel/blind_vlm/background/bk_3s.mp4" type="video/mp4">-->
<!--&lt;!&ndash;                    Your browser does not support the video tag.&ndash;&gt;-->
<!--                </video>-->
<!--            </div>-->
<!--             重复 .video-item 直到你添加完所有的视频 -->

        </div>

        <h2 class="title is-3"></h2>

                <h2 class="title is-3"></h2>

                <h2 class="title is-3"></h2>

                <h2 class="title is-3"></h2>

        <h4 class="title is-5"> </h4>
        <hr />

        <h4 class="title is-5"><u>Technology for good</u>, let's take action! </h4>


    </section>



    <section class="section" id="dataset">
        <h2 class="title is-3">Walking Awareness Dataset</h2>

        <hr />
        <h4 class="title is-5">Annotation pipeline</h4>

<!--        <hr />-->
            <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="1280"
                    height="160" src="assets/mannul_process.jpg"></td>
        <center>
            <h5 class="title is-6 left-align">The data annotation pipeline for constructing the walking awareness dataset. </h5>
        </center>


        <hr />
        <h4 class="title is-5">Geographical distribution</h4>

<!--        <hr />-->
<!--            <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="1000" height="120" src="assets/map.jpg"></td>-->
<td style="padding-left: 0px; padding-bottom: 0px;">
    <img class="center" width="667" height="80" src="assets/map.jpg" style="display: block; margin-left: auto; margin-right: auto;">
</td>
        <center>
            <h5 class="title is-6 left-align">Visualization results of the WAD dataset sorted by region.
    The WAD dataset has a wide range of sources, and the samples and categories shown are randomly obtained from the dataset.
    The pie chart in the lower left corner shows the proportion of video length from different regions. </h5>
        </center>

       <hr />
        <h4 class="title is-5">Compared to other datasets</h4>

<!--        <hr />-->
            <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="1280"
                    height="160" src="assets/data_data.png"></td>
        <center>
            <h5 class="title is-6 left-align"> Static information comparison of different datasets in blind walking task. WAD dataset holds a significant advantage in terms of sample numbers, categories, and modalities.</h5>
        </center>


        <hr />
        <h4 class="title is-5">Samples</h4>


    </section>


    <section class="section" id="methods">
        <hr />
        <h2 class="title is-3"> WalkVLM</h2>

        <h4 class="title is-5"> Framework </h4>

            <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="1280"
                    height="160" src="assets/fig_main.png"></td>
        <center>
            <h5 class="title is-6 left-align">    An overview of the proposed WalkVLM framework.
    WalkVLM employs CoT-based hierarchical planning to summarize the static attributes and understanding of scenes, thereby facilitating the subsequent reminder and QA tasks.
    Furthermore, temporal-aware adaptive prediction has been proposed to calculate the trigger state of VLM, thereby reducing the temporal redundancy of outputs.</h5>
        </center>

    </section>



    <section class="section" id="Results">
        <hr />
        <h2 class="title is-3"> Results</h2>

        <h4 class="title is-5"> Quantitative results </h4>

            <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="1280"
                    height="160" src="assets/results.png"></td>
        <center>
            <h5 class="title is-6 left-align">   Quantitative comparison of different methods on reminder and QA tasks.
WalkVLM leads in almost all the TF-IDF, ROUGE, and GPT Score metrics.
The higher the metric, the better the result.
Bold and underline indicate the best and the second-best, respectively.</h5>
        </center>

        <hr />
        <h4 class="title is-5"> Qualitative results </h4>

            <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="1280"
                    height="160" src="assets/visual.png"></td>
        <center>
            <h5 class="title is-6 left-align">       Visualization comparison of different VLM models.
    Compared to other models, WalkVLM is able to generate concise and informative answers, providing users with a good experience in blind walking.</h5>
        </center>


                <hr />
        <h4 class="title is-5"> Streaming inference </h4>

    </section>





  <section class="section" id="Vision">
        <hr />

        <h2 class="title is-3"> Vision</h2>

    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <p>
                We are committed to providing walking assistance to approximately 200 million visually impaired individuals worldwide through Vision-Language Model (VLM) technology, improving their quality of life. We have introduced the WalkVLM model and the Walking Awareness Dataset (WAD), aimed at generating concise and informative walking reminders.
                We call on all sectors of society to pay more attention to this group, promote technology for good, and help them better integrate into society. At the same time, we hope to further improve the model and dataset by crowdsourcing more data and resources, making our services more comprehensive and effective.
            </p>
          </div>
        </div>
      </div>




<!--           <section class="section" id="visual">-->
<!--        <hr />-->
<!--        <h2 class="title is-3">TASD Dataset</h2>-->
<!--        </center>-->
<!--        <table align="center">-->
<!--                <div class="center-text">-->
<!--                </div>-->
<!--                <br>-->
<!--                <tr>-->
<!--                    <td width="95" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Trigger Word</b></td>-->
<!--                    <td width="225" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Description</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>GIF</b></td>-->
<!--                    <td width="95" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Trigger Word</b></td>-->
<!--                    <td width="225" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Description</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>GIF</b></td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td width="95" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px"><br><br><br>unhappy</td>-->
<!--                    <td width="225" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px">In the picture, a cute little brown owl is sitting on the ground with its eyes closed, giving people a drowsy feeling. There is a can of Coca-Cola next to the owl.</td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/datasets/16f3e2a469c090cd091cae658a313f95.gif"></td>-->

<!--                    <td width="95" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px"><br><br><br>hit you</td>-->
<!--                    <td width="225" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px">The main character is a small green frog with a crown on its head, looking angry or grumpy. The frog is placed in the center of the picture, wearing a blue vest.</td>-->
<!--                     <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/datasets/325aaea940cae35b66794a0218e76c30.gif"></td>-->

<!--              </tr>-->

<!--                <tr>-->
<!--                    <td width="95" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px"><br><br><br>wow</td>-->
<!--                    <td width="225" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px">A cat is drawn simply with large eyes. The cat is sitting and looking up with a surprised or curious expression on his face, as if he has seen something unexpected or intriguing. The cat's appearance and expression bring a playful and cute quality to this image.</td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/datasets/f4a760c679147f4b6c2a36c22d2c4f5f.gif"></td>-->

<!--                    <td width="95" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px"><br><br><br>shy</td>-->
<!--                    <td width="225" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px">A cute pink and white pig with a big mouth stands in the center of the picture. The pig looks like it is smiling or expressing happiness because it has a big eye and round face appearance.</td>-->
<!--                     <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/datasets/3540f06fa1f9f84611f3ff0955554493.gif"></td>-->

<!--              </tr>-->

<!--                <tr>-->
<!--                    <td width="95" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px"><br><br><br>good night</td>-->
<!--                    <td width="225" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px">The main character is a small cartoon character wearing a white coat and glasses, who looks like a doctor or an alien. The character is depicted lying on a bed covered with a blanket, giving a feeling of comfort and warmth.</td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/datasets/6953290d8eb654a7237ae870bed3fdc1.gif"></td>-->

<!--                    <td width="95" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px"><br><br><br>hi</td>-->
<!--                    <td width="225" valign="center" halign="center" align="center"-->
<!--                        style="font-size:14px">A large green lizard-like creature is shown sitting on the floor, absorbed in a book. The lizard appears to be enjoying the book, showing curiosity and a hint of excitement as it reads. This whimsical creature presents a unique and interesting perspective on the joy of reading.</td>-->
<!--                     <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/datasets/988c59368053696d6bb7132dcc46fbe6.gif"></td>-->

<!--              </tr>-->


<!--            </table>-->

<!--    </section>-->

<!--    <section class="section" id="results">-->
<!--        <hr />-->
<!--        <h2 class="title is-3">Compare to Other Methods</h2>-->
<!--        </center>-->
<!--        <table align="center">-->
<!--                <div class="center-text">-->
<!--                </div>-->
<!--                <br>-->
<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i></i></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Src Img</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>MattingAnything[1]</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>SAM[2]</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>SAM2[3]</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>LayerDiffusion[4]</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Ours</b></td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case1 RGB</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_Matting.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_SAM1.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_SAM2.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_LayerDiffusion.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_ILDiff.gif"></td>-->
<!--                </tr>-->
<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case1 Alpha</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_AGT_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_Matting_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_SAM1_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_SAM2_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_LayerDiffusion_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/0a80956f8fb3a561dafd9b3f1929a060_ILDiff_alpha.gif"></td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case2 RGB</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_Matting.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_SAM1.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_SAM2.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_LayerDiffusion.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_ILDiff.gif"></td>-->
<!--                </tr>-->
<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case2 Alpha</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_AGT_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_Matting_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_SAM1_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_SAM2_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_LayerDiffusion_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a16d6bdf90a3de54f6322c28212ad56_ILDiff_alpha.gif"></td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case3 RGB</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_Matting.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_SAM1.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_SAM2.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_LayerDiffusion.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_ILDiff.gif"></td>-->
<!--                </tr>-->
<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case3 Alpha</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_AGT_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_Matting_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_SAM1_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_SAM2_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_LayerDiffusion_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6d64aed1b448b47e34b598be7f7261ce_ILDiff_alpha.gif"></td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case4 RGB</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_Matting.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_SAM1.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_SAM2.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_LayerDiffusion.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_ILDiff.gif"></td>-->
<!--                </tr>-->
<!--                <tr>-->
<!--                    <td width="50" valign="middle" halign="left" align="left"-->
<!--                        style="font-size:13px; padding-bottom:20px">&nbsp;&nbsp;<i>Case4 Alpha</i></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_AGT_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_Matting_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_SAM1_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_SAM2_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_LayerDiffusion_alpha.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/6a71e15c9e69c9ceef1d4ef2ca5ac7c7_ILDiff_alpha.gif"></td>-->
<!--                </tr>-->

<!--            </table>-->

<!--    </section>-->





<!--    <section class="section" id="visual">-->
<!--        <hr />-->
<!--        <h2 class="title is-3">More Results</h2>-->
<!--        </center>-->
<!--        <table align="center">-->
<!--                <div class="center-text">-->
<!--                </div>-->
<!--                <br>-->
<!--                <tr>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Input GIF</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Output GIF</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Input GIF</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Output GIF</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Input GIF</b></td>-->
<!--                    <td width="145" valign="middle" halign="middle" align="center"-->
<!--                        style="font-size:14px"><b>Output GIF</b></td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/fc563d7521cefcead81b013bf3700a95_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/fc563d7521cefcead81b013bf3700a95_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/f67c7ca4d1f3118a6555183c9f2015ed_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/f67c7ca4d1f3118a6555183c9f2015ed_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/f0f4ea9af3e3f9988d9093491fc6806b_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/f0f4ea9af3e3f9988d9093491fc6806b_ILDiff.gif"></td>-->

<!--              </tr>-->

<!--                <tr>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/e84417be7f802826125a0a41acea3c80_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/e84417be7f802826125a0a41acea3c80_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/f0bb494be297874049872bc2e8ada9d6_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/f0bb494be297874049872bc2e8ada9d6_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/dff6a2dbb2e2f5dddbb1902fd69f5306_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/dff6a2dbb2e2f5dddbb1902fd69f5306_ILDiff.gif"></td>-->

<!--              </tr>-->

<!--                <tr>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/dec12ff05b767c02c135a51de68fe9ad_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/dec12ff05b767c02c135a51de68fe9ad_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d13677224c2abe770e0e87605d13270c_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d13677224c2abe770e0e87605d13270c_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d170a6e13d18a9c742117762b715e890_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d170a6e13d18a9c742117762b715e890_ILDiff.gif"></td>-->

<!--              </tr>-->

<!--                <tr>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d28f09edfd4d442f2a642d217e24d11f_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d28f09edfd4d442f2a642d217e24d11f_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d7d693e7134ad1823d15e7ac2cec08a4_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/d7d693e7134ad1823d15e7ac2cec08a4_ILDiff.gif"></td>-->

<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/c04ef49cee431d28e6d28fb6e7b29b3c_AGT_rgb.gif"></td>-->
<!--                    <td align="center" style="padding-left: 0px; padding-bottom: 0px;"><img class="center" width="145"-->
<!--                            height="145" src="assets/compare_methods/c04ef49cee431d28e6d28fb6e7b29b3c_ILDiff.gif"></td>-->

<!--              </tr>-->

<!--            </table>-->

<!--    </section>-->





    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <p> If you use our work in your research, please cite: </p>
          <pre><code>
            @misc{anonymous2024WalkVLM,
            title={WalkVLM: Aid Visually Impaired People Walking by Vision Language Model},
            author={Anonymous},
            archivePrefix={arXiv},
            primaryClass={cs.CV}}
      </code></pre>
        </div>
      </section>



<!--
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <i class="fas fa-file-pdf"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>[1] Jonathan Ho, Tim Salimans, Alexey A Gritsenko, William Chan, Mohammad Norouzi, and David
                            J Fleet. Video
                            diffusion models. In
                            ICLR, 2022.</p>
                        <p>[2] Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Liu, and Jie Tang. Cogvideo: Large-scale
                            pretraining for
                            text-to-video generation
                            via transformers. In ICLR, 2023.</p>
                        <p>[3] Luo, Zhengxiong and Chen, Dayou and Zhang, Yingya and Huang, Yan and Wang, Liang and Shen, Yujun and Zhao, Deli and Zhou, Jingren and Tan, Tieniu
                            VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation. In CVPR, 2023.</p>

                        <p>[4] He, Yingqing, et al. "Latent video diffusion models for high-fidelity video generation with arbitrary lengths." arXiv preprint(2022).</p>


                        <hr>
                        <p>
                            Tempolate from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, thanks!
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
-->
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <i class="fas fa-file-pdf"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>[8] Haiying Xia, Cong Yao, Yumei Tan, and Shuxiang Song. A dataset for the visually impaired walk on the road. Displays, 79:102486, 2023.</p>
                        <p>[9] Danna Gurari, Qing Li, Abigale J Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, and Jeffrey P Bigham. Vizwiz grand challenge: Answering visual questions from blind people. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3608–3617,586 2018.</p>
                        <p>[11] Hao Wang, Jiayou Qin, Ashish Bastola, Xiwen Chen, John Suchanek, Zihao Gong, and Abolfazl Razi. Visiongpt: Llm-assisted real-time anomaly detection for safe visual navigation. arXiv preprint arXiv:2403.12415, 2024.</p>
                        <p>[17] Zain Merchant, Abrar Anwar, Emily Wang, Souti Chat-topadhyay, and Jesse Thomason. Generating contextually relevant navigation instructions for blind and low vision people. arXiv preprint arXiv:2407.08219, 2024.</p>
                        <p>[24] Wu Tang, De-er Liu, Xiaoli Zhao, Zenghui Chen, and Chen Zhao. A dataset for the recognition of obstacles on blind sidewalk. Universal Access in the Information Society, 22(1):69–82, 2023.</p>
                        <p>[36] Yuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang, Junbo Cui, Hongji Zhu, Tianchi Cai, Haoyu Li, Weilin Zhao, Zhihui He, et al. Minicpm-v: A gpt-4v level mllm on your phone. arXiv preprint arXiv:2408.01800, 2024.</p>
                        <p>[38] Md Touhidul Islam, Imran Kabir, Elena Ariel Pearce, Md Alimoor Reza, and Syed Masum Billah. Identifying crucial objects in blind and low-vision individuals’ navigation. arXiv preprint arXiv:2408.13175, 2024.</p>
                        <p>[42] Haoyu Lu, Wen Liu, Bo Zhang, Bingxuan Wang, Kai Dong, Bo Liu, Jingxiang Sun, Tongzheng Ren, Zhuoshu Li, Hao Yang, et al. Deepseek-vl: towards real-world vision-language understanding. arXiv preprint arXiv:2403.05525, 2024.</p>
                        <p>[43] lex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, et al. Yi: Open foundation models by 01. ai. arXiv preprint arXiv:2403.04652, 2024.</p>
                        <p>[44] Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276, 2024.</p>
                        <p>[45] Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin. Qwen2-vl: Enhancing vision-language model’s perception of the world at any resolution. arXiv preprint arXiv:2409.12191, 2024.</p>
                        <hr>
                    </div>
                </div>
            </div>
        </div>
    </footer>


</body>
